<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>text-mining on trang1618</title>
    <link>/tags/text-mining/</link>
    <description>Recent content in text-mining on trang1618</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <managingEditor>grixor@gmail.com (Trang Le)</managingEditor>
    <webMaster>grixor@gmail.com (Trang Le)</webMaster>
    <lastBuildDate>Fri, 22 Aug 2014 16:07:42 +0000</lastBuildDate>
    
	<atom:link href="/tags/text-mining/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>More ESA 2014 Program Text-Mining: Topics as Communities</title>
      <link>/archives/2014-08-22-topicmodeling/</link>
      <pubDate>Fri, 22 Aug 2014 16:07:42 +0000</pubDate>
      <author>grixor@gmail.com (Trang Le)</author>
      <guid>/archives/2014-08-22-topicmodeling/</guid>
      <description>In [my first pass at text analysis of the ESA program](http://www.noamross.net/blog/2014/7/24/esacorpuscompare.html), I looked at how the frequency of words used in the ESA program differed from last year to this year. There are much more sophisticated ways at looking at word use in text, though, and I began to dive into the text-mining literature to find other ways to draw insight from ESA abstracts. One method I found is *topic modeling* using [latent Dirichlet allocation](http://en.</description>
    </item>
    
  </channel>
</rss>